# ğŸ“… Medical Appointment Scheduling
## EDA, Machine Learning & MLflow

## ğŸ“Œ Description

Ce projet est une preuve de concept complÃ¨te en machine learning appliquÃ©e Ã  un jeu de donnÃ©es de planification de rendez-vous mÃ©dicaux.  
Il couvre lâ€™ensemble du pipeline data science : analyse exploratoire, prÃ©traitement, modÃ©lisation, optimisation des hyperparamÃ¨tres, suivi des expÃ©riences avec MLflow et interprÃ©tabilitÃ© des modÃ¨les avec SHAP.

Lâ€™objectif principal est de prÃ©dire le statut dâ€™un rendez-vous mÃ©dical (honorÃ© ou non) et dâ€™identifier les facteurs influenÃ§ant lâ€™absence des patients.

---

## ğŸ¯ Objectifs

- Analyser les donnÃ©es de rendez-vous mÃ©dicaux
- PrÃ©dire le statut des rendez-vous
- Comparer plusieurs modÃ¨les de machine learning
- Suivre et reproduire les expÃ©riences avec MLflow
- Expliquer les prÃ©dictions du modÃ¨le avec SHAP

---

## ğŸ“Š Jeu de donnÃ©es

- Source : Kaggle  
  https://www.kaggle.com/datasets/carogonzalezgaltier/medical-appointment-scheduling-system

- Variable cible :
  - `status` : statut du rendez-vous 

ğŸ“ Le fichier principal doit Ãªtre placÃ© dans :
    - data/raw/appointments.csv

Avant de commencer, assurez-vous de **tÃ©lÃ©charger le fichier appointments.csv** depuis Kaggle et de le placer dans ce dossier.

---

## ğŸ› ï¸ Technologies utilisÃ©es

- Python 3
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn
- MLflow
- SHAP
- Jupyter Notebook

---

## ğŸš€ Installation

```bash
git clone https://github.com/LamariAzzeddine/medical-appointment-scheduling.git
cd medical-appointment-scheduling


## CrÃ©er un environnement virtuel et lâ€™activer
python -m venv .venv
.venv\Scripts\activate

## Installer les dÃ©pendances :
pip install -r requirements.txt



##ğŸ“ˆ Analyse exploratoire (EDA)

    - Le notebook "notebooks/01_eda.ipynb" permet de :

        - Explorer la structure des donnÃ©es
        - Analyser la distribution de la variable cible
        - Identifier les valeurs manquantes
        - DÃ©tecter dâ€™Ã©ventuelles fuites de donnÃ©es

Note : Pour de meilleurs rÃ©sultats, il est recommandÃ© dâ€™exÃ©cuter les cellules du notebook pas Ã  pas, dans lâ€™ordre, afin de suivre correctement le flux dâ€™analyse et les visualisations.


## ğŸ”„ PrÃ©traitement des donnÃ©es
python src/data/make_dataset.py --input data/raw/appointments_filtre.csv --output data/processed/final.csv --target status


Le fichier prÃ©traitÃ© est gÃ©nÃ©rÃ© dans :
  - data/processed/final.csv




## ğŸ§  EntraÃ®nement des modÃ¨les

### 1ï¸âƒ£ Modeles de base (baselines)

| Nom | Type | Description |
|-----|------|-------------|
| `logreg` | Logistic Regression | RÃ©gression logistique simple, rÃ©fÃ©rence initiale. |
| `rf` | Random Forest | ModÃ¨le dâ€™ensemble robuste, capture les interactions entre variables. |

- EntraÃ®nÃ©s **sans optimisation des hyperparamÃ¨tres**  
- Fournissent un **benchmark initial**  
- Ã‰valuÃ©s avec : `accuracy`, `precision`, `recall`, `f1`, `roc_auc`, matrice de confusion et **score mÃ©tier** (moyenne prÃ©cision + rappel)  

### 2ï¸âƒ£ ModÃ¨le optimisÃ© : XGBoost

| Nom | Type | Optimisation |
|-----|------|-------------|
| `xgb` | XGBoost (`XGBClassifier`) | HyperparamÃ¨tres optimisÃ©s avec `GridSearchCV` : `max_depth`, `learning_rate`, `subsample`, `colsample_bytree` |

- SÃ©lection du meilleur modÃ¨le via **score mÃ©tier** `(precision + recall)/2`  
- ModÃ¨le final sauvegardÃ© dans `outputs/best_model.joblib`  
- Suivi des mÃ©triques et du modÃ¨le avec **MLflow**  


EntraÃ®ner les modÃ¨les :
python src/models/train.py --data data/processed/final.csv --target status


Lancer lâ€™interface MLflow :
    - mlflow ui


Les mÃ©triques, paramÃ¨tres et modÃ¨les sont enregistrÃ©s dans MLflow:
    - http://localhost:5000/


## ğŸ” InterprÃ©tabilitÃ© avec SHAP
    python -m src.models.explain --data data/processed/final.csv --target status --run-id <MLFLOW_RUN_ID>
    
<MLFLOW_RUN_ID> : ID du BEST_MODEL

SHAP global : importance des variables
SHAP local : explication des prÃ©dictions individuelles

- Les resultats de shap seront stockÃ©s dans le dossier "reports"

## ğŸ“ Structure du projet
.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ notebooks
â”‚   â””â”€â”€ 01_eda.ipynb
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â””â”€â”€ make_dataset.py
â”‚   â””â”€â”€ models
â”‚       â”œâ”€â”€ train.py
â”‚       â””â”€â”€ explain.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md



